<!DOCTYPE html>
<html lang="en">
	<head>
		<title>three.js PathTracing Renderer</title>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, user-scalable=no, initial-scale=1">
		<style>
			
			body {
				color: #ffffff;
				font-family:Monospace;
				font-size:13px;
				text-align:center;
				font-weight: bold;

				background-color: #000000;
				margin: 0px;
				overflow: hidden;
			}
			
			#instructions {
			
				font-family: arial;
				font-weight: bold;
				width: 100%;
				height: 100%;
				position: fixed;
				top: 35%;
				color: #ffffff;
				text-align: center;
				cursor: pointer;
			
			}

			#info {
				position: absolute;
				top: 0px; width: 100%;
				padding: 5px;
			}

			a {

				color: #ffffff;
			}

			#oldie a { color:#da0 }
		</style>
	</head>
	<body>

		<div id="container"></div>
		<div id="info"> three.js PathTracing Renderer</div>
		
		<div id="instructions">
		<span style="font-size:40px"></span>
		</div>
		
		
		<div id="debug" style="position:fixed; left:3%; bottom:1%; font-family:arial; font-type:bold; color:rgb(255,255,255);">
		samples: 0
		</div>

		<script src="js/three-r79.min.js"> </script>
		<script src="js/threex.keyboardstate.js"> </script>
		<script src="js/FirstPersonCameraControls.js"> </script>
		<script src="js/virtualButtonJoystick.js"> </script>

		<script src="js/Detector.js"> </script>
		<script src="js/stats.min.js"> </script>
		
		
		<script id="screenTextureVertexShader" type="x-shader/x-vertex">

varying vec2 vUv;

void main() {

	vUv = uv;
	gl_Position = vec4(position, 1.0);

}

		</script>
		
		<script id="screenTextureFragmentShader" type="x-shader/x-fragment">
		
varying vec2 vUv;
uniform sampler2D tTexture0;


void main() {
	
	gl_FragColor = texture2D(tTexture0, vUv);
	
}
		
		</script>
		
		<script id="screenOutputVertexShader" type="x-shader/x-vertex">

varying vec2 vUv;

void main() {

	vUv = uv;
	gl_Position = vec4( position, 1.0 );

}

		</script>
		
		<script id="screenOutputFragmentShader" type="x-shader/x-fragment">
		
varying vec2 vUv;
uniform sampler2D tTexture0;

void main() {

	vec4 pixelColor = texture2D(tTexture0, vUv);
	
	// apply gamma correction
	pixelColor = pow(pixelColor, vec4(0.4545));
	
	gl_FragColor = pixelColor;
	
}
		
		</script>
		


		<script id="pathTracingVertexShader" type="x-shader/x-vertex">
	
varying vec2 vUv;

void main()
{
	vUv = uv;
	gl_Position = vec4(position, 1.0);
}

		</script>
		
		
		
		<script id="pathTracingFragmentShader" type="x-shader/x-fragment">
				
precision highp float;

uniform vec2 uResolution;
uniform float uTime;
uniform float uSampleCounter;
uniform float uULen;
uniform float uVLen;
uniform float uRandomNumbers[16];

uniform mat4 uCameraMatrix;
//uniform mat4 uSphereMeshesMatrix[4];

uniform vec3 uRandomVector;

uniform sampler2D tPreviousTexture;

varying vec2 vUv;


#define PI 3.14159265359

#define SPHERE_ID 0
#define PLANE_ID 1
#define DISK_ID 2

#define N_SPHERES 9
#define N_PLANES 3
#define N_DISKS 2

#define DIFF 0
#define REFR 1
#define SPEC 2
#define CHECK 3


float seed = 0.0;
float rand()
{ 
	seed += uTime * (uRandomNumbers[0] + uRandomNumbers[1] + uRandomNumbers[2]);
	return fract(sin(seed)*43758.5453123);
}


//-----------------------------------------------------------------------

struct Ray { vec3 origin; vec3 direction; };
struct Sphere { float radius; vec3 position; vec3 emission; vec3 color; int type; };
struct Plane { vec4 pla; vec3 emission; vec3 color; int type; };
struct Disk { float radiusSq; vec3 pos; vec3 normal; vec3 emission; vec3 color; int type; };
struct Intersection { vec3 hitPoint; vec3 normal; vec3 emission; vec3 color; int type; int id; };

Sphere spheres[N_SPHERES];
Plane planes[N_PLANES];
Disk disks[N_DISKS];


//-----------------------------------------------------------------------
void SetupScene(void)
//-----------------------------------------------------------------------
{
	vec3 z = vec3(0.0);
	vec3 L1 = vec3(1.0, 1.0, 1.0) * 1.0;// White light
	vec3 L2 = vec3(1.0, 0.8, 0.2) * 2.0;// Yellowish light
	vec3 L3 = vec3(0.1, 0.5, 1.0) * 3.0;// Bluish light
		
        spheres[0] = Sphere( 10000.0, vec3(0.0, -10000.0, 0.0), z, vec3(0.6,0.6,0.6), CHECK);//Checkered Floor
	
        spheres[1] = Sphere( 800.0, vec3(-400.0, 1100.0, 40.0), L1, vec3(1.0,1.0,1.0), DIFF);//Light1 sphere
	spheres[2] = Sphere( 100.0, vec3(300.0, 300.0, -300.0), L2, vec3(1.0,1.0,1.0), DIFF);//Light2 sphere
	spheres[3] = Sphere( 80.0, vec3(400.0, 150.0, 0.0),    L3, vec3(1.0,1.0,1.0), DIFF);//Light3 sphere
	
        spheres[4] = Sphere( 16.5, vec3(-16.0,16.5,5.0), z, vec3(0.8,0.8,0.8), SPEC);//Mirror sphere
        spheres[5] = Sphere( 16.5, vec3(32.0,16.5,40.0), z, vec3(1.0,1.0,1.0), REFR);//Glass sphere
        spheres[6] = Sphere( 10.0, vec3(-30.0,10.0,50.0), z, vec3(1.0,1.0,1.0), DIFF);//White diffuse sphere
        spheres[7] = Sphere( .0001, vec3(32.0,16.5,40.0), z, vec3(1.0,1.0,0.0), DIFF);//Yellow diffuse sphere
        spheres[8] = Sphere( 5.0, vec3(5.0,5.0,35.0), z, vec3(1.0,1.0,1.0), DIFF);//White diffuse sphere

	planes[0]  = Plane( vec4( 0.0,0.0,1.0,50.0), z, vec3(1.0,1.0,1.0), DIFF);//WhitePlane Back Wall
	planes[1]  = Plane( vec4( 0.0,0.0,-1.0,100.0), z, vec3(1.0,1.0,1.0), DIFF);//WhitePlane Front Wall
	planes[2]  = Plane( vec4( 0.0,-1.0,0.0,70.0), z, vec3(1.0,1.0,1.0), DIFF);//WhitePlane Ceiling
	
	disks[0]   = Disk( 16.5 * 16.5, vec3(-60.0,13.0,-10.0), vec3( 1.0,-1.0,0.0 ), z, vec3(1.0,0.0,0.0), DIFF);//RedDisk Left 
	disks[1]   = Disk( 16.5 * 16.5, vec3( 30.0,-2.0,-200.0), vec3( -1.0,0.0,0.1 ), L3, vec3(1.0,1.0,1.0), DIFF);//DiskLight Right	
	
}

//-----------------------------------------------------------------------
float SphereIntersect( float rad, vec3 pos, Ray r )
//-----------------------------------------------------------------------
{
	vec3 op = pos - r.origin;
	float eps = 0.0001;
	float b = dot(op, r.direction);
	float det = b * b - dot(op,op) + rad * rad;
       	if (det < 0.0)
		return 0.0;
        
	det = sqrt(det);	
	float t1 = b - det;
	if( t1 > eps )
		return t1;
		
	float t2 = b + det;
	if( t2 > eps )
		return t2;

	return 0.0;	
}

//-----------------------------------------------------------------------
float PlaneIntersect( vec4 pla, Ray r )
//-----------------------------------------------------------------------
{
	vec3 n = normalize(-pla.xyz);
	float denom = dot(n, r.direction);
	float t = -1.0;
	
    	if (denom > 0.0)
	{ 
        	vec3 pOrO = (pla.w * n) - r.origin; 
        	t = dot(pOrO, n) / denom; 
        	//return (t >= 0);
    	}
	return t;
}

//-----------------------------------------------------------------------
float DiskIntersect( float radiusSq, vec3 diskPos, vec3 normal, Ray r )
//-----------------------------------------------------------------------
{
	vec3 n = normalize(-normal);
	float denom = dot(n, r.direction);
	float t = -1.0;
	
    	if (denom > 0.0)
	{ 
		vec3 pOrO = diskPos - r.origin;
        	t = dot(pOrO, n) / denom; 
        	vec3 intersectPos = r.origin + r.direction * t;
		vec3 v = intersectPos - diskPos;
		float d2 = dot(v,v);
		if (d2 > radiusSq)
		{
			t = -1.0;
		} 
    	}
	return t;
}


//-----------------------------------------------------------------------
bool SceneIntersect( Ray r, inout float t, inout Intersection intersec )
//-----------------------------------------------------------------------
{
	float d;
	float inf = 100000.0;
	t   = inf;
	
        for (int i = 0; i < N_SPHERES; i++)
        {
		d = SphereIntersect( spheres[i].radius , spheres[i].position , r );
		if (d > 0.0 && d < t)
		{
			t = d;
			intersec.hitPoint = r.origin + r.direction * t;
			intersec.normal = normalize(intersec.hitPoint - spheres[i].position);
			intersec.emission = spheres[i].emission;
			intersec.color = spheres[i].color;
			intersec.type = spheres[i].type;
			intersec.id = SPHERE_ID;
		}
        }
	/*
	for (int j = 0; j < N_PLANES; j++)
        {
		d = PlaneIntersect( planes[j].pla , r );
		if (d >= 0.0 && d < t)
		{
			t = d;
			intersec.hitPoint = r.origin + r.direction * t;
			intersec.normal = (planes[j].pla.xyz);
			intersec.emission = planes[j].emission;
			intersec.color = planes[j].color;
			intersec.type = planes[j].type;
			intersec.id = PLANE_ID;
		}
        }
	*/
	for (int k = 0; k < N_DISKS; k++)
        {
		d = DiskIntersect( disks[k].radiusSq, disks[k].pos, disks[k].normal, r );
		if (d >= 0.0 && d < t)
		{
			t = d;
			intersec.hitPoint = r.origin + r.direction * t;
			intersec.normal = normalize(disks[k].normal);
			intersec.emission = disks[k].emission;
			intersec.color = disks[k].color;
			intersec.type = disks[k].type;
			intersec.id = DISK_ID;
		}
        }
	
	return t < inf;
}

//-----------------------------------------------------------------------
vec3 CalculateRadiance( Ray r )
//-----------------------------------------------------------------------
{
	vec3 finalCol = vec3(0.0,0.0,0.0);
        vec3 fCum = vec3(1.0,1.0,1.0);
        Intersection intersec;
	
	         // don't go above 14 for uRandomNumbers[] array bounds
        for (int depth = 0; depth < 5; depth++)
        {

                float t = 0.0;    // distance to intersection
                intersec.emission = vec3(0.0);
		if (!SceneIntersect(r, t, intersec))
                    break;
		
		vec3 x = intersec.hitPoint;
		vec3 n = normalize(intersec.normal);
                vec3 nl = dot(n,r.direction) < 0.0 ? n : n * -1.0;
		nl = normalize(nl);
                vec3 f = intersec.color;
		
		/*
		// Russian Roulette
                float p = max(max(f.x,f.y),f.z);
                if ( rand() < p)
                    f = f / p;
                else
                    break;
		*/
		
		fCum *= f;
	
		// we reached something bright, don't spawn any more rays
		if (intersec.emission.r > 0.1 || intersec.emission.g > 0.1 || intersec.emission.b > 0.1 )
		{
			finalCol = fCum * intersec.emission;
			break;
		}

                if (intersec.type == DIFF || intersec.type == CHECK) // Ideal DIFFUSE reflection
                {
			
			if( intersec.type == CHECK )
			{
				if( (mod(x.x,60.0) < 30.0 && mod(x.z,60.0) < 30.0) || 
					(mod(x.x,60.0) > 30.0 && mod(x.z,60.0) > 30.0) )
				fCum *= 0.5;					
			}
		
			seed -= (uRandomNumbers[depth] + uRandomNumbers[depth+2]);

                	float r1 = 2.0 * 3.1415926536 * rand();
                	float r2 = rand();
                	float r2s = sqrt(r2);
                	vec3 w = nl;
			vec3 u = normalize(cross( (abs(w.x) > 0.1 ? vec3(0.0, 1.0, 0.0) : vec3(1.0,1.0,1.0)) , w));
			vec3 v = cross(w,u);
                	vec3 d = normalize(u * cos(r1) * r2s + v * sin(r1) * r2s + w * sqrt(1.0 - r2));
			
                	r = Ray(x, d);
			r.origin += r.direction; // avoid self-intersection
                	continue;
                }
                else 
	        if (intersec.type == SPEC)  // Ideal SPECULAR reflection
                {
                        r = Ray(x, r.direction - n * 2.0 * dot(n,r.direction));
			
			r.origin += r.direction; // avoid self-intersection
                        continue;
                }

                // Ideal dielectric REFRACTION
                Ray reflRay = Ray(x, r.direction - n * 2.0 * dot(n,r.direction)); 
		
		bool into = dot(n,nl) > 0.0;  // Ray from outside going in?

                float nc = 1.0;   // IOR of air
                float nt = 1.5; // IOR of solid
                float nnt = into ? nc / nt : nt / nc;
                float ddn = dot(r.direction , nl);
                float cos2t = 1.0 - nnt * nnt * (1.0 - ddn * ddn);

                if (cos2t < 0.0)    // Total internal reflection
                {
                    r = reflRay;
		    r.origin += r.direction; // avoid self-intersection
                    continue;
                }

                vec3 tdir = normalize(r.direction * nnt - n * ((into ? 1.0 : -1.0) * (ddn * nnt + sqrt(cos2t))));

                float a = nt - nc;
                float b = nt + nc;
                float R0 = a * a / (b * b);
                float c = 1.0 - (into ? -ddn : dot(tdir,n));
                float Re = R0 + (1.0 - R0) * c * c * c * c * c;
                float Tr = 1.0 - Re;
                float P = .25 + .5 * Re;
                float RP = Re / P;
                float TP = Tr / (1.0 - P);
		
                if( rand() < P )
                {
                    r = reflRay;
		    r.origin += r.direction; // avoid self-intersection
                    fCum = fCum * RP;
                }
                else
                {
                    r = Ray(x, tdir);
		    r.origin += r.direction; // avoid self-intersection
                    fCum = fCum * TP;
                }
						

            }

            return finalCol;
}



void main( void )
{

	vec3 camPos = vec3(uCameraMatrix[3][0], uCameraMatrix[3][1], uCameraMatrix[3][2]);
	
    	vec3 camRight   = ( vec3( uCameraMatrix[0][0],  uCameraMatrix[0][1],  uCameraMatrix[0][2]) );
    	vec3 camUp      = ( vec3( uCameraMatrix[1][0],  uCameraMatrix[1][1],  uCameraMatrix[1][2]) );
	vec3 camForward = ( vec3(-uCameraMatrix[2][0], -uCameraMatrix[2][1], -uCameraMatrix[2][2]) );
	
	//rng seed
	seed = uSampleCounter * uRandomNumbers[0] + uResolution.y * gl_FragCoord.x / uResolution.x + gl_FragCoord.y / uResolution.y;
	float r1 = 2.0 * rand();
	float r2 = 2.0 * rand();
			
	float dx = r1 < 1.0 ? sqrt(r1) - 1.0 : 1.0 - sqrt(2.0 - r1);
        float dy = r2 < 1.0 ? sqrt(r2) - 1.0 : 1.0 - sqrt(2.0 - r2);
	
	dx = (dx + gl_FragCoord.x) / uResolution.x - 0.5;
	dy = (dy + gl_FragCoord.y) / uResolution.y - 0.5;
	
	vec3 rayDir = normalize( dx * camRight * uULen + dy * camUp * uVLen + camForward );
	
	Ray ray = Ray( camPos , rayDir );
	
	SetupScene();
	     		
	// perform path tracing and get resulting pixel color
	vec4 pixelColor = vec4( CalculateRadiance(ray), 1.0);
	vec4 previousColor = texture2D(tPreviousTexture, vUv);
	
	pixelColor = (previousColor * uSampleCounter + pixelColor) / (uSampleCounter + 1.0);
	gl_FragColor = clamp(pixelColor,0.0,1.0);
	
}

		</script>
		
		
		<script>

			if ( ! Detector.webgl ) Detector.addGetWebGLMessage();

			var SCREEN_WIDTH = window.innerWidth;
			var SCREEN_HEIGHT = window.innerHeight;
			var container, stats;
			var controls;
			var pathTracingGeometry, pathTracingMaterial, pathTracingMesh; // rtt = render to texture
			var screenOutputGeometry, screenOutputMaterial, screenOutputMesh;
			var screenTextureGeometry, screenTextureMaterial, screenTextureMesh;
			var groundGeometry, checkeredMaterial, groundMesh;
			var boxGeometry, blueMaterial, boxMesh;
			var sphereGeometry, mirrorMaterial, whiteMaterial, glassMaterial;
			var sphereMesh = [];
			var pointLight00, pointLight01, pointLight02;
			var quadCamera, worldCamera;
			var renderer, clock;
			var pathTracingRenderTarget, screenOutputRenderTarget;
			var screenOutputScene, screenTextureScene, pathTracingScene; // RTT = Render To Texture
			var fovScale;
			var frameTime, elapsedTime;
			var pathTracingUniforms, screenOutputUniforms, screenTextureUniforms;
			var pixelRatio = 1.0;
			var TWO_PI = Math.PI * 2;
			var randomVector = new THREE.Vector3();
			var randomNumbers = [];
			var sampleCounter = 0.0;
			var stopTime = 10.0;
			var keyboard = new THREEx.KeyboardState();
			var isPaused = true;
			var oldYawRotation, oldPitchRotation;
			var camFlightSpeed = 40;
			var fontAspect;

			// are we in portrait mobile view? if so, move the buttons over to the left a little..
			// if not and we are in landscape mode, they can safely be moved farther right without running into each other
			var b2PercentLeft = SCREEN_WIDTH < SCREEN_HEIGHT ? 50 : 65;
			var b1PercentLeft = SCREEN_WIDTH < SCREEN_HEIGHT ? 77 : 81;
			var b3PercentLeft = Math.floor( (b1PercentLeft + b2PercentLeft) / 2 );
			var joystick = new VirtualJoystick({
				add3Buttons: true,
				hideJoystick: true,
				hideButtons: false,
				button1PercentLeft: b1PercentLeft,
				button2PercentLeft: b2PercentLeft,
				button3PercentLeft: b3PercentLeft
			});

			var PI_2 = Math.PI / 2;//used by controls below
			
			var infoElement = document.getElementById( 'info' );
			infoElement.style.cursor = "default";
			infoElement.style.webkitUserSelect = "none";
			infoElement.style.MozUserSelect = "none";
			
			var instructionsElement = document.getElementById( 'instructions' );
			instructionsElement.style.cursor = "default";
			instructionsElement.style.webkitUserSelect = "none";
			instructionsElement.style.MozUserSelect = "none";
			
			var debugElement = document.getElementById( 'debug' );
			debugElement.style.cursor = "default";
			debugElement.style.webkitUserSelect = "none";
			debugElement.style.MozUserSelect = "none";
			
			var mouseControl = true;
			// if not on a mobile device, enable mouse control 
			if ( 'createTouch' in document ) {
				mouseControl = false;
				pixelRatio = 0.7;
			}
			
			// if on mobile device, unpause the app because there is no ESC key and no mouse capture to do
			if ( !mouseControl )
				isPaused = false;
			
			if (mouseControl) {
	
				instructionsElement.innerHTML = 'Paused <br> Click to start';

				document.body.addEventListener("click", function() {
					this.requestPointerLock = this.requestPointerLock || this.mozRequestPointerLock;
					this.requestPointerLock();
				}, false);


				window.addEventListener("mousedown", function(event) {
					if ( !isPaused ) {
						if(event.button === 0) {
							
						}	
						else if(event.button === 2) {
							
						}
					}	
				}, false);

				window.addEventListener("click", function(event) {
					event.preventDefault();	
				}, false);
				window.addEventListener("dblclick", function(event) {
					event.preventDefault();	
				}, false);


				var pointerlockChange = function ( event ) {

					if ( document.pointerLockElement === instructionsElement || document.mozPointerLockElement === instructionsElement || document.webkitPointerLockElement === instructionsElement ||
						document.pointerLockElement === document.body || document.mozPointerLockElement === document.body || document.webkitPointerLockElement === document.body ) {

						instructionsElement.style.display = 'none';
						isPaused = false;

					} else {

						instructionsElement.style.display = '';
						isPaused = true;

					}

				};

				// Hook pointer lock state change events
				document.addEventListener( 'pointerlockchange', pointerlockChange, false );
				document.addEventListener( 'mozpointerlockchange', pointerlockChange, false );
				document.addEventListener( 'webkitpointerlockchange', pointerlockChange, false );

			}

			// the following variables will be used to calculate rotations and directions from the camera
			var cameraDirectionVector = new THREE.Vector3();//for moving where the camera is looking
			var cameraRightVector = new THREE.Vector3();//for strafing the camera right and left
			var cameraUpVector = new THREE.Vector3();//for moving camera up and down
			var cameraWorldQuaternion = new THREE.Quaternion();//for rotating scene objects to match camera's current rotation
			var cameraControlsObject;//for positioning and moving the camera itself
			var cameraControlsYawObject;//allows access to control camera's left/right movements through mobile input
			var cameraControlsPitchObject;//allows access to control camera's up/down movements through mobile input

			
			
			init();
			animate();

			function init() {

				container = document.getElementById( 'container' );
				renderer = new THREE.WebGLRenderer();
				// 1 is full resolution, 0.5 is half, 0.25 is quarter, etc. (must be > than 0.0)
				renderer.setPixelRatio(pixelRatio);
				
				container.appendChild( renderer.domElement );

				stats = new Stats();
				stats.domElement.style.position = 'absolute';
				stats.domElement.style.top = '0px';
				container.appendChild( stats.domElement );
				
				window.addEventListener( 'resize', onWindowResize, false );
				
				clock = new THREE.Clock();
				
				pathTracingScene = new THREE.Scene();
				screenOutputScene = new THREE.Scene();
				screenTextureScene = new THREE.Scene();
				
				// quadCamera is simply the camera to help render the full screen quad (2 triangles),
				// hence the name.  It is an Orthographic camera that sits facing the view plane, which serves as
				// the window into our 3d world. This camera will not move or rotate for the duration of the app.
				quadCamera = new THREE.OrthographicCamera( -1, 1, 1, -1, 0, 1 );
				screenOutputScene.add(quadCamera);
				screenTextureScene.add(quadCamera);
				
				// worldCamera is the dynamic camera 3d object that will be positioned, oriented and 
				// constantly updated inside the 3d scene.  Its view will ultimately get passed back to the 
				// stationary quadCamera, which renders the scene to a fullscreen quad (made up of 2 large triangles).
				worldCamera = new THREE.PerspectiveCamera(90, window.innerWidth / window.innerHeight, 1, 1000);
				pathTracingScene.add(worldCamera);
				
				controls = new FirstPersonCameraControls( worldCamera );
							
				cameraControlsObject = controls.getObject();
				cameraControlsYawObject = controls.getYawObject();
				cameraControlsPitchObject = controls.getPitchObject();
				
				pathTracingScene.add( cameraControlsObject );

				// for flyCam
				cameraControlsObject.position.set(0,35,95);
				cameraControlsYawObject.rotation.y = 0.0;
				// look slightly downward
				cameraControlsPitchObject.rotation.x = -0.4;
				joystick.previousRotationX = -0.4;
				
				
				pathTracingRenderTarget = new THREE.WebGLRenderTarget( Math.floor(window.innerWidth * pixelRatio), Math.floor(window.innerHeight * pixelRatio), {
					minFilter: THREE.NearestFilter, // default THREE.LinearMipMapLinearFilter
					magFilter: THREE.NearestFilter, // default THREE.LinearFilter
					format: THREE.RGBAFormat,
					depthBuffer: false,
					stencilBuffer: false
				} );
				pathTracingRenderTarget.texture.generateMipmaps = false;
				//pathTracingRenderTarget.texture.needsUpdate = true;
				
				screenOutputRenderTarget = new THREE.WebGLRenderTarget( Math.floor(window.innerWidth * pixelRatio), Math.floor(window.innerHeight * pixelRatio), {
					minFilter: THREE.NearestFilter, 
					magFilter: THREE.NearestFilter, 
					format: THREE.RGBAFormat,
					depthBuffer: false,
					stencilBuffer: false
				} );
				screenOutputRenderTarget.texture.generateMipmaps = false;
				//screenOutputRenderTarget.texture.needsUpdate = true;
				
	
				
				pathTracingGeometry = new THREE.PlaneBufferGeometry( 2, 2 );

				pathTracingUniforms = {
					
					tPreviousTexture: { type: "t", value: screenOutputRenderTarget.texture },
					
					uTime: { type: "f", value: 0.0 },
					uSampleCounter: { type: "f", value: 0.0 },
					uULen: { type: "f", value: 1.0 },
					uVLen: { type: "f", value: 1.0 },
					
					uRandomNumbers: { type: "fv", value: [] },
					
					uResolution: { type: "v2", value: new THREE.Vector2() },
					
					uRandomVector: { type: "v3", value: new THREE.Vector3() },
				
					uCameraMatrix: { type: "m4", value: new THREE.Matrix4() },
	
				};
			
				pathTracingMaterial = new THREE.ShaderMaterial( {
					uniforms: pathTracingUniforms,
					vertexShader: document.getElementById( 'pathTracingVertexShader' ).textContent,
					fragmentShader: document.getElementById( 'pathTracingFragmentShader' ).textContent,
				        depthTest: false,
                                        depthWrite: false
                                } );

				pathTracingMesh = new THREE.Mesh( pathTracingGeometry, pathTracingMaterial );
				pathTracingScene.add( pathTracingMesh );
				
				// the following keeps the large scene ShaderMaterial quad right in front 
				//   of the camera at all times. This is necessary because without it, the scene 
				//   quad will fall out of view and get clipped when the camera rotates past 180 degrees.
				worldCamera.add( pathTracingMesh );
				
				
				
				screenTextureGeometry = new THREE.PlaneBufferGeometry( 2, 2 );
				
				screenTextureUniforms = {
					tTexture0: { type: "t", value: pathTracingRenderTarget.texture }
				}
				
				screenTextureMaterial = new THREE.ShaderMaterial( {
					uniforms: screenTextureUniforms,
					vertexShader: document.getElementById( 'screenTextureVertexShader' ).textContent,
					fragmentShader: document.getElementById( 'screenTextureFragmentShader' ).textContent,
					depthWrite: false,
					depthTest: false
				} );
				
				screenTextureMesh = new THREE.Mesh(screenTextureGeometry, screenTextureMaterial);
				screenTextureScene.add(screenTextureMesh);
				
				
				
			
				screenOutputGeometry = new THREE.PlaneBufferGeometry( 2, 2 );
				
				screenOutputUniforms = {
					tTexture0: { type: "t", value: screenOutputRenderTarget.texture }
				}
				
				screenOutputMaterial = new THREE.ShaderMaterial( {
					uniforms: screenOutputUniforms,
					vertexShader: document.getElementById( 'screenOutputVertexShader' ).textContent,
					fragmentShader: document.getElementById( 'screenOutputFragmentShader' ).textContent,
					depthWrite: false,
					depthTest: false
				} );
				
				screenOutputMesh = new THREE.Mesh(screenOutputGeometry, screenOutputMaterial);
				screenOutputScene.add(screenOutputMesh);

				
					
				// this must be at the end of the init() function
				onWindowResize();

			} // end function init()
			
			

			function onWindowResize( event ) {
				
				renderer.setSize( window.innerWidth, window.innerHeight );
				
				SCREEN_WIDTH = window.innerWidth;
				SCREEN_HEIGHT = window.innerHeight;
				
				fontAspect = (SCREEN_WIDTH / 175) * (SCREEN_HEIGHT / 200);
				if (fontAspect > 25) fontAspect = 25;
				if (fontAspect < 4) fontAspect = 4;
				fontAspect *= 2;
				instructionsElement.style.fontSize = fontAspect + "px";
	

				pathTracingUniforms.uResolution.value.x = Math.floor(window.innerWidth * pixelRatio);
				pathTracingUniforms.uResolution.value.y = Math.floor(window.innerHeight * pixelRatio);
				
				pathTracingRenderTarget.setSize( window.innerWidth * pixelRatio, window.innerHeight * pixelRatio );
				screenOutputRenderTarget.setSize( window.innerWidth * pixelRatio, window.innerHeight * pixelRatio );
				
				worldCamera.aspect = window.innerWidth / window.innerHeight;
				worldCamera.updateProjectionMatrix();
				
				// the following scales all scene objects by the worldCamera's field of view,
				// taking into account the screen aspect ratio and multiplying the uniform uULen,
				// the x-coordinate, by this ratio
				fovScale = worldCamera.fov * 0.5 * (Math.PI / 180.0);
				pathTracingUniforms.uVLen.value = Math.tan(fovScale);
				pathTracingUniforms.uULen.value = pathTracingUniforms.uVLen.value * worldCamera.aspect;
				
				// check if mobile device is in portrait or landscape mode and position buttons accordingly
				b2PercentLeft = SCREEN_WIDTH < SCREEN_HEIGHT ? 50 : 65;
				joystick._button2El.style.left = b2PercentLeft + "%";
				b1PercentLeft = SCREEN_WIDTH < SCREEN_HEIGHT ? 77 : 81;
				joystick._button1El.style.left = b1PercentLeft + "%";
				joystick._button3El.style.left = Math.floor( (b1PercentLeft + b2PercentLeft) / 2 ) + "%";
				if (SCREEN_WIDTH < SCREEN_HEIGHT ) {
					joystick._button3El.style.bottom = 11 + "%";
				}
				else if (SCREEN_WIDTH > SCREEN_HEIGHT ) {
					joystick._button3El.style.bottom = 21 + "%";
				}
				
				
			}
			


			function animate() {
				
				requestAnimationFrame( animate );

				frameTime = clock.getDelta();
				
				elapsedTime = clock.getElapsedTime() % 1000;
				pathTracingUniforms.uTime.value = elapsedTime;
				
				pathTracingUniforms.uRandomVector.value = randomVector.set( Math.random(), Math.random(), Math.random() );
				
				for ( var i = 0; i < 16; i ++ ) {
					randomNumbers[i] = Math.random();
				}
				
				pathTracingUniforms.uRandomNumbers.value = randomNumbers;
				
				
				debugElement.innerHTML = "samples: " + sampleCounter;
				
				
				// check user controls
				
				if (oldYawRotation != cameraControlsYawObject.rotation.y){
					sampleCounter = 0.0;
				}
				if (oldPitchRotation != cameraControlsPitchObject.rotation.x) {
					sampleCounter = 0.0;
				}
				// save state for next frame
				oldYawRotation = cameraControlsYawObject.rotation.y;
				oldPitchRotation = cameraControlsPitchObject.rotation.x;
			
				// if not playing on desktop, get the rotation from the mobile-touch virtual Joystick
				if (!mouseControl) {

					cameraControlsYawObject.rotation.y = joystick.previousRotationY - joystick.deltaX() * 0.005;
					cameraControlsPitchObject.rotation.x = joystick.previousRotationX - joystick.deltaY() * 0.005;
					// clamp the camera's vertical movement (around the x-axis) to the 'ceiling' and 'floor',
					// so you can't accidentally flip the camera upside down
					cameraControlsPitchObject.rotation.x = Math.max( - PI_2, Math.min( PI_2, cameraControlsPitchObject.rotation.x ) );

					if (joystick.deltaX() || joystick.deltaY()) {
						sampleCounter = 0.0;
					}
				}
				
				// this gives us a vector in the direction that the camera is pointing,
				// which will be useful for moving the camera 'forward' and shooting projectiles in that direction
				controls.getDirection(cameraDirectionVector);
				//cameraDirectionVector.normalize();
				controls.getUpVector(cameraUpVector);
				controls.getRightVector(cameraRightVector);

				// the following gives us a rotation quaternion (4D vector), which will be useful for 
				// rotating scene objects to match the camera's rotation
				worldCamera.getWorldQuaternion(cameraWorldQuaternion);
				
				// allow flying camera
				if ( joystick.button3Pressed || keyboard.pressed('W') ) {

					cameraControlsObject.position.add(cameraDirectionVector.multiplyScalar(camFlightSpeed * frameTime));
					sampleCounter = 0.0;
				}
				if ( keyboard.pressed('S') ) {

					cameraControlsObject.position.sub(cameraDirectionVector.multiplyScalar(camFlightSpeed * frameTime));
					sampleCounter = 0.0;
				}
				if ( joystick.button1Pressed || keyboard.pressed('D') ) {

					cameraControlsObject.position.add(cameraRightVector.multiplyScalar(camFlightSpeed * frameTime));
					sampleCounter = 0.0;
				}
				if ( keyboard.pressed('A') ) {

					cameraControlsObject.position.sub(cameraRightVector.multiplyScalar(camFlightSpeed * frameTime));
					sampleCounter = 0.0;
				}
				if ( joystick.button2Pressed || keyboard.pressed('Q') ) {

					cameraControlsObject.position.add(cameraUpVector.multiplyScalar(camFlightSpeed * frameTime));
					sampleCounter = 0.0;
				}
				if ( keyboard.pressed('Z') ) {

					cameraControlsObject.position.sub(cameraUpVector.multiplyScalar(camFlightSpeed * frameTime));
					sampleCounter = 0.0;
				}
				
					
				// CAMERA
				///cameraControlsObject.position.set( (Math.sin(elapsedTime * 0.25)) * 8, 3 + (2.5 * Math.sin(elapsedTime * 0.2)), 1 );			
				pathTracingUniforms.uCameraMatrix.value.copy( worldCamera.matrixWorld );
					
				
				// RENDERING in 3 steps
				
				// STEP 1
				// Perform PathTracing and Render into pathTracingRenderTarget
				// Read previous screenOutputRenderTarget to use as a new starting point to blend with
				renderer.render( pathTracingScene, worldCamera, pathTracingRenderTarget );
				
				
				// STEP 2
				// render(save) the final scene output into screenOutputRenderTarget
				// This will be used as a new starting point for Step 1 above
				renderer.render( screenTextureScene, quadCamera, screenOutputRenderTarget );
				
				// STEP 3
				// Render full screen quad with generated screenOutputRenderTarget above.
				// After this image is gamma corrected, it will be shown on the screen as the final output
				renderer.render( screenOutputScene, quadCamera );
				
				pathTracingUniforms.uSampleCounter.value = sampleCounter;
				sampleCounter += 1.0;
				if (sampleCounter > 10000.0) {
					sampleCounter = 10000.0;
				}
				
				stats.update();
					
			} // end function animate()

		</script>

	</body>
</html>
