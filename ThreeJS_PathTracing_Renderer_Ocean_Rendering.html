<!DOCTYPE html>
<html lang="en">
	<head>
		<title>three.js PathTracing Renderer - Ocean Rendering</title>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, user-scalable=no, initial-scale=1">
		<style>

			html, body {
				width: 100%;
				height: 100%;
				font-family: Monospace;
				background-color: #000;
				color: #000;
				margin: 0px;
				overflow: hidden;
			}
			
			#info {
				position: absolute;
				top: 5px;
				width: 100%;
				text-align: center;
				color: #ffffff;
			}		
			
		</style>
	</head>
	<body>

		<div id="container"> </div>
		<div id="info">three.js PathTracing Renderer - Ocean Rendering</div>
		
		<div id="cameraInfo" style="position:fixed; left:3%; bottom:2%; font-family:arial; font-type:bold; color:rgb(255,255,255);">
		FOV: 50 / Aperture: 0.00 / FocusDistance: 1160 <br> 
		Samples: 0
		</div>

		<script src="js/three-r85.min.js"> </script>
		<script src="js/threex.keyboardstate.js"> </script>
		<script src="js/FirstPersonCameraControls.js"> </script>
		<script src="js/MobileJoystickControls.js"> </script>
		<!-- <script src="js/webgl-obj-loader.js"> </script> -->
		<script src="js/Detector.js"> </script>
		<script src="js/stats.min.js"> </script>
		
		
		<script id="screenTextureVertexShader" type="x-shader/x-vertex">

precision highp float;
precision highp int;

varying vec2 vUv;

void main()
{
	vUv = uv;
	gl_Position = vec4( position, 1.0 );

}

		</script>
		
		<script id="screenTextureFragmentShader" type="x-shader/x-fragment">

precision highp float;
precision highp int;
precision highp sampler2D;

varying vec2 vUv;
uniform sampler2D tTexture0;


void main()
{	
	gl_FragColor = texture2D(tTexture0, vUv);	
}
		
		</script>
		
		<script id="screenOutputVertexShader" type="x-shader/x-vertex">

precision highp float;
precision highp int;

varying vec2 vUv;

void main() 
{
	vUv = uv;
	gl_Position = vec4( position, 1.0 );
}

		</script>
		
		<script id="screenOutputFragmentShader" type="x-shader/x-fragment">

precision highp float;
precision highp int;
precision highp sampler2D;

varying vec2 vUv;
uniform float uOneOverSampleCounter;
uniform sampler2D tTexture0;

void main()
{
	vec4 pixelColor = texture2D(tTexture0, vUv) * uOneOverSampleCounter;
	
	gl_FragColor = sqrt(pixelColor);	
}
		
		</script>
		


		<script id="pathTracingVertexShader" type="x-shader/x-vertex">
		
precision highp float;
precision highp int;

varying vec2 vUv;

void main()
{
	vUv = uv;
	gl_Position = vec4( position, 1.0 );
}

		</script>
		
		
		
		<script id="pathTracingFragmentShader" type="x-shader/x-fragment">
				
precision highp float;
precision highp int;
precision highp sampler2D;


uniform bool uCameraIsMoving;
uniform bool uCameraJustStartedMoving;

uniform float uTime;
uniform float uSampleCounter;
uniform float uULen;
uniform float uVLen;
uniform float uApertureSize;
uniform float uFocusDistance;

uniform vec2 uResolution;

//uniform vec3 uMeshBBox_min;
//uniform vec3 uMeshBBox_max;

uniform vec3 uRandomVector;

uniform mat4 uCameraMatrix;
//uniform mat4 uSphereMeshesMatrix[4];
uniform mat4 uTallBoxMeshMatrix;
uniform mat4 uTallBoxMeshInvMatrix;
uniform mat4 uShortBoxMeshMatrix;
uniform mat4 uShortBoxMeshInvMatrix;

uniform mat4 uShortBoxMatrix4x4;
uniform mat3 uShortBoxNormalMatrix3x3;
uniform mat4 uTallBoxMatrix4x4;
uniform mat3 uTallBoxNormalMatrix3x3;

uniform sampler2D tPreviousTexture;
//uniform sampler2D tTriangleTexture;

varying vec2 vUv;

#define PI               3.14159265358979323
#define ONE_OVER_PI      0.31830988618379067
#define TWO_PI           6.28318530717958648
#define FOUR_PI          12.5663706143591729
#define ONE_OVER_FOUR_PI 0.07957747154594767
#define PI_OVER_TWO      1.57079632679489662
//#define E                2.71828182845904524
#define INFINITY         9000000.0

#define SPHERE_ID 0
#define PLANE_ID 1
#define DISK_ID 2
#define TRIANGLE_ID 3
#define QUAD_ID 4
#define BOX_ID 5
#define ELLIPSOID_ID 6
#define OPENCYLINDER_ID 7


#define N_QUADS 5
#define N_BOXES 3
#define N_OPENCYLINDERS 4

#define LIGHT 0
#define DIFF 1
#define REFR 2
#define SPEC 3
#define CHECK 4
#define COAT 5
#define VOLUME 6
#define TRANSLUCENT 7
#define SPECSUB 8
#define WOOD 9
#define SEAFLOOR 10

const float turbidity = 2.0;
const float rayleighCoefficient = 4.0;

const float mieCoefficient = 0.01;
const float mieDirectionalG = 0.76;

// constants for atmospheric scattering
const float THREE_OVER_SIXTEENPI = 0.05968310365946075;
const float ONE_OVER_FOURPI = 0.07957747154594767;

// wavelength of used primaries, according to preetham
const vec3 lambda = vec3( 680E-9, 550E-9, 450E-9 );
// this pre-calcuation replaces the older totalRayleigh(vec3 lambda) function which was:
// return (8.0 * (pi*pi*pi) * pow(n*n - 1.0, 2.0) * (6.0 + 3.0 * pn)) / (3.0 * N * pow(lambda, vec3(4.0)) * (6.0 - 7.0 * pn));
const vec3 totalRayleigh = vec3( 5.804542996261093E-6, 1.3562911419845635E-5, 3.0265902468824876E-5 );

// mie stuff
// K coefficient for the primaries
const vec3 K = vec3(0.686, 0.678, 0.666);
const float v = 4.0;
//const vec3 MieConst = PI * pow((2.0 * PI) / lambda, vec3(v - 2.0)) * K;
const vec3 MieConst = vec3( 1.8399918514433978E14, 2.7798023919660528E14, 4.0790479543861094E14 );

// optical length at zenith for molecules
const float rayleighZenithLength = 8400.0;
const float mieZenithLength = 1250.0;
const vec3 up = vec3(0.0, 1.0, 0.0);

const float sunIntensity = 800.0;
const float sunAngularDiameterCos = 0.99983194915; // 66 arc seconds -> degrees, and the cosine of that

// earth shadow hack
const float cutoffAngle = 1.65346981768;// (PI / 1.9)


float seed = 0.0;

float rand()
{ 
	seed -= uRandomVector.x * uRandomVector.y;
	return fract( sin( seed ) * 43758.5453123 );
}


//-----------------------------------------------------------------------

struct Ray { vec3 origin; vec3 direction; };
struct OpenCylinder { float radius; vec3 pos1; vec3 pos2; vec3 emission; vec3 color; int type; };
struct Quad { vec3 v0; vec3 v1; vec3 v2; vec3 v3; vec3 emission; vec3 color; int type; };
struct Box { vec3 minCorner; vec3 maxCorner; vec3 emission; vec3 color; int type; };
struct Intersection { vec3 normal; vec3 emission; vec3 color; int type; int id; };

OpenCylinder openCylinders[N_OPENCYLINDERS];
Quad quads[N_QUADS];
Box boxes[N_BOXES];


//---------------------------------------------------------------------------
float OpenCylinderIntersect( float rad, vec3 p0, vec3 p1, Ray r, out vec3 n )
//---------------------------------------------------------------------------
{
	float r2=rad*rad;
	
	vec3 dp=p1-p0;
	vec3 dpt=dp/dot(dp,dp);
	
	vec3 ao=r.origin-p0;
	vec3 aoxab=cross(ao,dpt);
	vec3 vxab=cross(r.direction,dpt);
	float ab2=dot(dpt,dpt);
	float a=2.0*dot(vxab,vxab);
	float ra=1.0/a;
	float b=2.0*dot(vxab,aoxab);
	float c=dot(aoxab,aoxab)-r2*ab2;
	
	float det=b*b-2.0*a*c;
	
	if(det<0.0)
	return INFINITY;
	
	det=sqrt(det);
	
	float t = INFINITY;
	
	float t0=(-b-det)*ra;
	float t1=(-b+det)*ra;
	
	vec3 ip;
	vec3 lp;
	float ct;
	
	if (t1 > 0.0)
	{
		ip=r.origin+r.direction*t1;
		lp=ip-p0;
		ct=dot(lp,dpt);
		if((ct>0.0)&&(ct<1.0))
		{
			t = t1;
		     	n=(p0+dp*ct)-ip;
		}
		
	}
	
	if (t0 > 0.0)
	{
		ip=r.origin+r.direction*t0;
		lp=ip-p0;
		ct=dot(lp,dpt);
		if((ct>0.0)&&(ct<1.0))
		{
			t = t0;
			n=ip-(p0+dp*ct);
		}
		
	}
	
	return t;
}

//---------------------------------------------------------
float TriangleIntersect( vec3 v0, vec3 v1, vec3 v2, Ray r )
//---------------------------------------------------------
{
	vec3 edge1 = v1 - v0;
	vec3 edge2 = v2 - v0;
	vec3 tvec = r.origin - v0;
	vec3 pvec = cross(r.direction, edge2);
	float det = 1.0 / dot(edge1, pvec);
	float u = dot(tvec, pvec) * det;

	if (u < 0.0 || u > 1.0)
		return INFINITY;

	vec3 qvec = cross(tvec, edge1);

	float v = dot(r.direction, qvec) * det;

	if (v < 0.0 || u + v > 1.0)
		return INFINITY;

	return dot(edge2, qvec) * det;
}

//----------------------------------------------------------------------------
float QuadIntersect( vec3 v0, vec3 v1, vec3 v2, vec3 v3, Ray r )
//----------------------------------------------------------------------------
{
	float tTri1 = TriangleIntersect( v0, v1, v2, r );
	float tTri2 = TriangleIntersect( v0, v2, v3, r );
	return min(tTri1, tTri2);
}


//--------------------------------------------------------------------------
float BoxIntersect( vec3 minCorner, vec3 maxCorner, Ray r, out vec3 normal )
//--------------------------------------------------------------------------
{
	vec3 invDir = 1.0 / r.direction;
	vec3 tmin = (minCorner - r.origin) * invDir;
	vec3 tmax = (maxCorner - r.origin) * invDir;
	
	vec3 real_min = min(tmin, tmax);
	vec3 real_max = max(tmin, tmax);
	
	float minmax = min( min(real_max.x, real_max.y), real_max.z);
	float maxmin = max( max(real_min.x, real_min.y), real_min.z);
	
	// early out
	if (minmax < maxmin) return INFINITY;
	
	if (maxmin > 0.0) // if we are outside the box
	{
		normal = -sign(r.direction) * step(real_min.yzx, real_min) * step(real_min.zxy, real_min);
		return maxmin;	
	}
		
	if (minmax > 0.0) // else if we are inside the box
	{
		normal = -sign(r.direction) * step(real_max, real_max.yzx) * step(real_max, real_max.zxy);
		return minmax;
	}
				
	return INFINITY;
}

//---------------------------------------------------------------------------------------------------------
float DisplacementBoxIntersect( vec3 minCorner, vec3 maxCorner, Ray r, out vec3 normal, out float outside )
//---------------------------------------------------------------------------------------------------------
{
	vec3 invDir = 1.0 / r.direction;
	vec3 tmin = (minCorner - r.origin) * invDir;
	vec3 tmax = (maxCorner - r.origin) * invDir;
	
	vec3 real_min = min(tmin, tmax);
	vec3 real_max = max(tmin, tmax);
	
	float minmax = min( min(real_max.x, real_max.y), real_max.z);
	float maxmin = max( max(real_min.x, real_min.y), real_min.z);
	
	// early out
	if (minmax < maxmin) return INFINITY;
	
	if (maxmin > 0.0) // if we are outside the box
	{
		outside = 2.0;
		//normal = -sign(r.direction) * step(real_min.yzx, real_min) * step(real_min.zxy, real_min);
		//normal = normalize(normal);
		//if (normal.y > 0.9)
			return maxmin;	
	}
		
	if (minmax > 0.0) // else if we are inside the box
	{
		outside = -2.0;
		//normal = -sign(r.direction) * step(real_max, real_max.yzx) * step(real_max, real_max.zxy);
		return minmax;
	}
				
	return INFINITY;
}



// sea
const int ITER_FRAGMENT =   4; // # of fractal iterations
const float SEA_HEIGHT = 50.0; // this is how many units down from the top of the ocean bounding box
const float SEA_FREQ =   0.08; // amount of wave detail: lower = spread out, higher = close together
const float SEA_CHOPPY =  2.0; // smaller beachfront-looking waves, they travel in parallel
const float SEA_SPEED =   3.0; // how quickly time passes

#define SEA_TIME (uTime * SEA_SPEED)
const mat2 octave_m = mat2(1.6,1.2,-1.2,1.6);

float hash( vec2 p )
{
	float h = dot(p,vec2(127.1,311.7));	
	return fract(sin(h)*43758.5453123);
}

float noise( in vec2 p )
{
	vec2 i = floor( p );
	vec2 f = fract( p );	
	vec2 u = f*f*(3.0-2.0*f);
	return -1.0+2.0*mix( mix( hash( i + vec2(0.0,0.0) ), 
		     hash( i + vec2(1.0,0.0) ), u.x),
		mix( hash( i + vec2(0.0,1.0) ), 
		     hash( i + vec2(1.0,1.0) ), u.x), u.y);
}

float sea_octave( vec2 uv, float choppy )
{
	uv += noise(uv);        
	vec2 wv = 1.0-abs(sin(uv));
	vec2 swv = abs(cos(uv));    
	wv = mix(wv,swv,wv);
	return pow(1.0-pow(wv.x * wv.y,0.65),choppy);
}

float getOceanWaterDepth( vec3 p )
{
	p.x *= 0.01; p.z *= 0.01;
	float freq = SEA_FREQ;
	float amp = SEA_HEIGHT;
	float choppy = SEA_CHOPPY;
	
	vec2 uv = p.xz; uv.x *= 0.75;

	float d, h = 0.0;    
	for(int i = 0; i < ITER_FRAGMENT; i++)
	{        
		d = sea_octave((uv+SEA_TIME)*freq,choppy);
		d += sea_octave((uv-SEA_TIME)*freq,choppy);
		h += d * amp;        
		uv *= octave_m; freq *= 1.9; amp *= 0.22;
		choppy = mix(choppy,1.0,0.2);
	}
	return p.y - h;
}


//----------------------------------------------------------------------
float SceneIntersect( Ray r, inout Intersection intersec)
//----------------------------------------------------------------------
{
        Ray rObj;
	vec3 hitObjectSpace;
	vec3 hitWorldSpace;
	vec3 normal, nw;
        float d, dw, dObj;
	float t = INFINITY;
        float eps = 0.01;
	float waterWaveDepth;
	float outside;
	
		
	for (int i = 0; i < N_QUADS; i++)
        {
		d = QuadIntersect( quads[i].v0, quads[i].v1, quads[i].v2, quads[i].v3, r );
		if (d < t && d > 0.0)
		{
			t = d;
			intersec.normal = normalize( cross(quads[i].v1 - quads[i].v0, quads[i].v2 - quads[i].v0) );
			intersec.emission = quads[i].emission;
			intersec.color = quads[i].color;
			intersec.type = quads[i].type;
			intersec.id = QUAD_ID;
		}
        }
	
	for (int i = 0; i < N_OPENCYLINDERS; i++)
        {
		d = OpenCylinderIntersect( openCylinders[i].radius, openCylinders[i].pos1, openCylinders[i].pos2, r, normal );
		if (d < t)
		{
			t = d;
			intersec.normal = normalize(normal);
			intersec.emission = openCylinders[i].emission;
			intersec.color = openCylinders[i].color;
			intersec.type = openCylinders[i].type;
			intersec.id = OPENCYLINDER_ID;
		}
        }
	
	// TALL MIRROR BOX
	// transform ray into Tall Box's object space
	rObj.origin = vec3( uTallBoxMatrix4x4 * vec4(r.origin, 1.0) );
	rObj.direction = vec3( uTallBoxMatrix4x4 * vec4(r.direction, 0.0) );
	d = BoxIntersect( boxes[0].minCorner, boxes[0].maxCorner, rObj, normal );
	
	if (d < t)
	{	
		t = d;
		// transfom normal back into world space
		normal = vec3(uTallBoxNormalMatrix3x3 * normal);
		intersec.normal = normalize(normal);
		intersec.emission = boxes[0].emission;
		intersec.color = boxes[0].color;
		intersec.type = boxes[0].type;
		intersec.id = BOX_ID;
	}
	
	
	// SHORT DIFFUSE WHITE BOX
	// transform ray into Short Box's object space
	rObj.origin = vec3( uShortBoxMatrix4x4 * vec4(r.origin, 1.0) );
	rObj.direction = vec3( uShortBoxMatrix4x4 * vec4(r.direction, 0.0) );
	d = BoxIntersect( boxes[1].minCorner, boxes[1].maxCorner, rObj, normal );
	
	if (d < t)
	{	
		t = d;
		// transfom normal back into world space
		normal = vec3(uShortBoxNormalMatrix3x3 * normal);
		intersec.normal = normalize(normal);
		intersec.emission = boxes[1].emission;
		intersec.color = boxes[1].color;
		intersec.type = boxes[1].type;
		intersec.id = BOX_ID;
	}
	
	///////////////////////////////////////////////////////////////////////////////////////////////////////
	// OCEAN BOX 
	///////////////////////////////////////////////////////////////////////////////////////////////////////
	
	
	d = BoxIntersect(boxes[2].minCorner, boxes[2].maxCorner, r, normal);
	if (d == INFINITY) return t;
	
	hitWorldSpace = r.origin + r.direction * d;
	waterWaveDepth = getOceanWaterDepth(hitWorldSpace);
	boxes[2].maxCorner.y = waterWaveDepth;
	
	dw = DisplacementBoxIntersect(boxes[2].minCorner, boxes[2].maxCorner, r, nw, outside);
	
	if (dw < t)
	{
		t = dw;
		hitWorldSpace = r.origin + r.direction * dw;
		float dx = getOceanWaterDepth(hitWorldSpace + vec3(eps,0,0)) - getOceanWaterDepth(hitWorldSpace + vec3(-eps,0,0));
		//float dy = eps + eps; // (the water wave height is a function of x and z, not dependent on y)
		float dy = getOceanWaterDepth(hitWorldSpace + vec3(0,eps,0)) - getOceanWaterDepth(hitWorldSpace + vec3(0,-eps,0));
		float dz = getOceanWaterDepth(hitWorldSpace + vec3(0,0,eps)) - getOceanWaterDepth(hitWorldSpace + vec3(0,0,-eps));
		intersec.normal = normalize(vec3(dx,dy,dz));
		intersec.emission = boxes[2].emission;
		intersec.color = boxes[2].color;
		intersec.type = boxes[2].type;
		intersec.id = BOX_ID;
	}
	
	return t;
}

vec3 randomSphereDirection()
{
    	vec2 r = vec2(rand(),rand())*TWO_PI;
	return vec3(sin(r.x)*vec2(sin(r.y),cos(r.y)),cos(r.x));	
}

vec3 randomCosWeightedDirectionInHemisphere(vec3 nl)
{
	float up = sqrt(rand()); // weighted cos(theta)
    	float over = sqrt(1.0 - up * up); // sin(theta)
    	float around = rand() * TWO_PI;
	vec3 u = normalize( cross( abs(nl.x) > 0.1 ? vec3(0, 1, 0) : vec3(1, 0, 0), nl ) );
	vec3 v = normalize( cross(nl, u) );
    	return vec3( cos(around) * over * u ) + ( sin(around) * over * v ) + (up * nl);		
}


float RayleighPhase(float cosTheta)
{
	return THREE_OVER_SIXTEENPI * (1.0 + (cosTheta * cosTheta));
}

float hgPhase(float cosTheta, float g)
{
        float g2 = g * g;
        float inverse = 1.0 / pow(1.0 - 2.0 * g * cosTheta + g2, 1.5);
	return ONE_OVER_FOURPI * ((1.0 - g2) * inverse);
}

vec3 totalMie(vec3 lambda, vec3 K, float T)
{
	float c = (0.2 * T ) * 10E-18;
	return 0.434 * c * PI * pow((TWO_PI) / lambda, vec3(v - 2.0)) * K;
}

float SunIntensity(float zenithAngleCos)
{
	return sunIntensity * max( 0.0, 1.0 - exp( -( cutoffAngle - acos(zenithAngleCos) ) ) );
}


vec3 Uncharted2ToneMap(vec3 color)
{
	float A = 0.15;
	float B = 0.50;
	float C = 0.10;
	float D = 0.20;
	float E = 0.02;
	float F = 0.30;
	float W = 11.2;
	float exposure = 0.2;//0.012
	color *= exposure;
	color = ((color * (A * color + C * B) + D * E) / (color * (A * color + B) + D * F)) - E / F;
	float white = ((W * (A * W + C * B) + D * E) / (W * (A * W + B) + D * F)) - E / F;
	color /= white;
	///color = pow(color, vec3(1. / gamma));
	return color;
}


vec3 Get_Sky_Color(Ray r, vec3 sunDirection)
{
	
    	vec3 viewDir = (r.direction);
	
	/* most of the following code is borrowed from the three.js shader file: SkyShader.js */

    	// Cosine angles
	float cosViewSunAngle = dot(viewDir, sunDirection);
    	float cosSunUpAngle = dot(sunDirection, up); // allowed to be negative: + is daytime, - is nighttime
    	float cosUpViewAngle = max(0.01, dot(up, viewDir)); // cannot be 0, used as divisor
	
        // Get sun intensity based on how high in the sky it is
    	float sunE = SunIntensity(cosSunUpAngle);
        
	// extinction (absorbtion + out scattering)
	// rayleigh coefficients
    	vec3 rayleighAtX = totalRayleigh * rayleighCoefficient;
    
	// mie coefficients
	vec3 mieAtX = totalMie(lambda, K, turbidity) * mieCoefficient;  
    
	// optical length
	float zenithAngle = 1.0 / cosUpViewAngle;
    
	float rayleighOpticalLength = rayleighZenithLength * zenithAngle;
	float mieOpticalLength = mieZenithLength * zenithAngle;

	// combined extinction factor	
	vec3 Fex = exp(-(rayleighAtX * rayleighOpticalLength + mieAtX * mieOpticalLength));

	// in scattering
	vec3 rayleighXtoEye = rayleighAtX * RayleighPhase(cosViewSunAngle);
	vec3 mieXtoEye = mieAtX *  hgPhase(cosViewSunAngle, mieDirectionalG);
     
    	vec3 totalLightAtX = rayleighAtX + mieAtX;
    	vec3 lightFromXtoEye = rayleighXtoEye + mieXtoEye; 
    
    	vec3 somethingElse = sunE * (lightFromXtoEye / totalLightAtX);
    
    	vec3 sky = somethingElse * (1.0 - Fex);
	float oneMinusCosSun = 1.0 - cosSunUpAngle;
    	sky *= mix( vec3(1.0), pow(somethingElse * Fex,vec3(0.5)), 
	    clamp(oneMinusCosSun * oneMinusCosSun * oneMinusCosSun * oneMinusCosSun * oneMinusCosSun, 0.0, 1.0) );

	// composition + solar disc
    	float sundisk = smoothstep(sunAngularDiameterCos,sunAngularDiameterCos, cosViewSunAngle + 0.0004);
	vec3 sun = (sunE * sunIntensity * Fex) * sundisk;

    	return Uncharted2ToneMap(sky + sun);
}


vec3 calcDirectLightingSun(vec3 mask, vec3 x, vec3 nl, vec3 sunDirection)
{
	vec3 dirLight = vec3(0.0);
	Intersection shadowIntersec;
	
	// cast shadow ray from intersection point
	Ray shadowRay = Ray( x, normalize( sunDirection + 
		(vec3(rand() * 2.0 - 1.0, rand() * 2.0 - 1.0, rand() * 2.0 - 1.0) * 0.01) ) );
	shadowRay.origin += nl * 2.0;
	float st = SceneIntersect(shadowRay, shadowIntersec);
	if ( st == INFINITY )
	{
		//float r2 = light.radius * light.radius;
		//vec3 d = light.position-shadowRay.origin;
		//float d2 = dot(d,d);
		//float cos_a_max = sqrt(1. - clamp( r2 / d2, 0., 1.));
                //float weight = 2. * (1. - cos_a_max);
		vec3 sunEmission = Get_Sky_Color(shadowRay, shadowRay.direction);
                dirLight = mask * sunEmission * max(0.01, dot(shadowRay.direction, nl));
	}
	
	return dirLight;
}


//-----------------------------------------------------------------------
vec3 CalculateRadiance( Ray r, vec3 sunDirection )
//-----------------------------------------------------------------------
{
	Ray cameraRay = r;
	vec3 accumCol = vec3(0.0);
        vec3 mask = vec3(1.0);
        Intersection intersec;
	bool bounceIsSpecular = true;
	
        for (int depth = 0; depth < 4; depth++)
	{
		
		float t = SceneIntersect(r, intersec);
		
		if (intersec.type == SEAFLOOR)
		{
			float waterDotSun = max(0.0, dot(vec3(0,1,0), sunDirection));
			accumCol = mask * intersec.color * waterDotSun;
				//* (1.0 / log(distance(cameraRay.origin, cameraRay.origin + cameraRay.direction * t )));
                        break;
		}
		
		if (t == INFINITY)
		{
			if (bounceIsSpecular)
			{
				accumCol += mask * Get_Sky_Color(r, sunDirection);
			}
			
                        break;
		}
		
		// useful data 
		vec3 n = intersec.normal;
                vec3 nl = dot(n,r.direction) <= 0.0 ? normalize(n) : normalize(n * -1.0);
		vec3 x = r.origin + r.direction * t;
		
		
                if (intersec.type == DIFF) // Ideal DIFFUSE reflection
                {
			mask *= intersec.color;
			accumCol += calcDirectLightingSun(mask, x, nl, sunDirection);
			
			// choose random Diffuse sample vector
			vec3 d = randomCosWeightedDirectionInHemisphere( nl );
                	r = Ray( x, normalize(d) );
			r.origin += r.direction * 2.0;
			bounceIsSpecular = false;
			continue;	
                }
		
                if (intersec.type == SPEC)  // Ideal SPECULAR reflection
                {
			mask *= intersec.color;
			r = Ray( x, reflect(r.direction, nl) );
			r.origin += r.direction * 2.0;
			
			bounceIsSpecular = true;
                        continue;
                }
		
		if (intersec.type == REFR)  // Ideal dielectric REFRACTION
		{
			float nc = 1.0; // IOR of air
			float nt = 1.33; // IOR of water
			float nnt = dot(n,nl) > 0.0 ? (nc / nt) : (nt / nc); // Ray from outside going in?
			vec3 tdir = refract(r.direction, nl, nnt);
				
			// Original Fresnel equations
			float cosThetaInc = dot(nl, r.direction);
			float cosThetaTra = dot(nl, tdir);
			float coefS = (nc * cosThetaInc - nt * cosThetaTra) / (nc * cosThetaInc + nt * cosThetaTra);
			float coefP = (nc * cosThetaTra - nt * cosThetaInc) / (nc * cosThetaTra + nt * cosThetaInc);
			float Re = ( (coefS * coefS) + (coefP * coefP) ) * 0.5; // Unpolarized
			//float Tr = 1.0 - Re;
			
			if (rand() < Re) // reflect ray from surface
			{
				r = Ray( x, reflect(r.direction, nl) );
				r.origin += r.direction * 2.0;
				bounceIsSpecular = true;
				continue;	
			}
			
			else // transmit ray through surface
			{
				mask *= intersec.color;
				r = Ray(x, tdir);
				r.origin += r.direction * 2.0;
				bounceIsSpecular = true;
				continue;
			}
			
			/*
			vec3 absorptionCoefficient = vec3(2.0, 0.01, 0.1);
			float translucentDensity = 0.0001;
			float scatteringDistance = -log(rand()) / translucentDensity;
			
			if (scatteringDistance < t) 
			{
				mask *= exp(-absorptionCoefficient * scatteringDistance); // scattering
				r.direction = normalize(randomSphereDirection()); // true Isotropic scattering
				bounceIsSpecular = true;
			}
			else
			{
				mask *= exp(-absorptionCoefficient * t); // transmission
				r.direction = tdir;
				bounceIsSpecular = true;
			}
			
			//accumCol += calcDirectLighting(mask, x, nl, spheres[0]);
			x = x + (r.direction * 2.0) * scatteringDistance;
			r = Ray( x, r.direction );
			continue;
			*/
		} // end if (intersec.type == REFR)
		
		if (intersec.type == WOOD || intersec.type == COAT)  // Diffuse object underneath with thin Water on top
		{
			float roughness = 0.2;
			float iOR = 1.01;
			
			// Schlick Fresnel approx.
			float ddn = dot(-r.direction, nl);
			float nc = 1.0; // IOR of air
			float nt = iOR; // IOR of ClearCoat 
			float R0 = (nc - nt) / (nc + nt);
			R0 *= R0;
			float c = 1.0 - ddn;
			float Re = R0 + (1.0 - R0) * c * c * c * c * c;
			
			// choose either specular reflection or diffuse
			if( rand() < Re )
			{	
				vec3 reflectVec = reflect(r.direction, nl);
				vec3 randVec = vec3(rand() * 2.0 - 1.0, rand() * 2.0 - 1.0, rand() * 2.0 - 1.0);
				r = Ray( x, mix( reflectVec, normalize(nl + randVec), roughness) );
				r.origin += r.direction * 2.0;
				bounceIsSpecular = true;
				continue;	
			}
			else
			{
				if(intersec.type == WOOD)
				{
					float pattern = abs(noise(vec2( (x.x * 0.5 * x.z * 0.5 + sin(x.y*0.005)) )));
					float woodPattern = 1.0 / max(1.0, pattern * 100.0);
					intersec.color *= vec3(woodPattern);
				}
				
				mask *= intersec.color;
				accumCol += calcDirectLightingSun(mask, x, nl, sunDirection);
				// choose random sample vector for diffuse material underneath ClearCoat
				vec3 d = randomCosWeightedDirectionInHemisphere( nl );
				r = Ray( x, normalize(d) );
				r.origin += r.direction * 2.0;
				bounceIsSpecular = false;
				continue;
			}
			
		} //end if (intersec.type == WOOD || intersec.type == COAT)
		
	} // end for (int depth = 0; depth < 4; depth++)
	
	return accumCol;      
}

//-----------------------------------------------------------------------
void SetupScene(void)
//-----------------------------------------------------------------------
{
	vec3 z  = vec3(0.0, 0.0, 0.0);// No color value, Black        
	float oceanFloorDepth = -1000.0;
	
	quads[0] = Quad( vec3(  0.0, 0.0,-559.2), vec3(549.6, 0.0,-559.2), vec3(549.6, 548.8,-559.2), vec3(  0.0, 548.8,-559.2),    z, vec3(1.0),  DIFF);// Back Wall
	quads[1] = Quad( vec3(  0.0, 0.0,   0.0), vec3(  0.0, 0.0,-559.2), vec3(  0.0, 548.8,-559.2), vec3(  0.0, 548.8,   0.0),    z, vec3(0.7, 0.12,0.05),  DIFF);// Left Wall Red
	quads[2] = Quad( vec3(549.6, 0.0,-559.2), vec3(549.6, 0.0,   0.0), vec3(549.6, 548.8,   0.0), vec3(549.6, 548.8,-559.2),    z, vec3(0.2, 0.4, 0.36),  DIFF);// Right Wall Green
	//quads[3] = Quad( vec3(  0.0, 548.8,-559.2), vec3(549.6, 548.8,-559.2), vec3(549.6, 548.8,   0.0), vec3(  0.0, 548.8,   0.0),    z, vec3(1.0),  DIFF);// Ceiling
	quads[3] = Quad( vec3(  0.0, 0.0,   0.0), vec3(549.6, 0.0,   0.0), vec3(549.6, 0.0,-559.2), vec3(  0.0, 0.0,-559.2),    z, vec3(1.0), DIFF);// Floor
	
	quads[4] = Quad( vec3( -1000000, oceanFloorDepth, 1000000), vec3(1000000, oceanFloorDepth, 1000000), vec3(1000000, oceanFloorDepth, -1000000), vec3( -1000000, oceanFloorDepth, -1000000), 
		z, vec3(0.0, 0.01, 0.008), SEAFLOOR);// Ocean Floor 
	
	openCylinders[0] = OpenCylinder( 50.0, vec3(50 , 0, -50), vec3(50 ,-1000, -50), z, vec3(0.1, 0.005, 0.0), WOOD);// wooden support OpenCylinder
	openCylinders[1] = OpenCylinder( 50.0, vec3(500, 0, -50), vec3(500,-1000, -50), z, vec3(0.1, 0.005, 0.0), WOOD);// wooden support OpenCylinder
	openCylinders[2] = OpenCylinder( 50.0, vec3(50 , 0,-510), vec3(50 ,-1000,-510), z, vec3(0.1, 0.005, 0.0), WOOD);// wooden support OpenCylinder
	openCylinders[3] = OpenCylinder( 50.0, vec3(500, 0,-510), vec3(500,-1000,-510), z, vec3(0.1, 0.005, 0.0), WOOD);// wooden support OpenCylinder
	
	boxes[0] = Box( vec3( -82.0,-170.0, -80.0), vec3(  82.0, 170.0,   80.0), z, vec3(0.9), SPEC);// Tall Mirror Box Left
	boxes[1] = Box( vec3( -86.0, -85.0, -80.0), vec3(  86.0,  85.0,   80.0), z, vec3(1.0), DIFF);// Short Diffuse Box Right
	
	boxes[2] = Box( vec3(-1000000, 2.0 * oceanFloorDepth, -1000000), vec3(1000000, 50.0, 1000000), z, vec3(0.65, 0.7, 0.68), REFR);// Ocean Box
}


void main( void )
{

	vec3 camPos     = vec3( uCameraMatrix[3][0],  uCameraMatrix[3][1],  uCameraMatrix[3][2]);
	
    	vec3 camRight   = vec3( uCameraMatrix[0][0],  uCameraMatrix[0][1],  uCameraMatrix[0][2]);
    	vec3 camUp      = vec3( uCameraMatrix[1][0],  uCameraMatrix[1][1],  uCameraMatrix[1][2]);
	vec3 camForward = vec3(-uCameraMatrix[2][0], -uCameraMatrix[2][1], -uCameraMatrix[2][2]);
	
	// seed for rand() function
	seed = mod(uSampleCounter,1000.0) * uRandomVector.x - uRandomVector.y + uResolution.y * gl_FragCoord.x / uResolution.x + uResolution.x * gl_FragCoord.y / uResolution.y;
	
	float r1 = 2.0 * rand();
	float r2 = 2.0 * rand();
	
	vec2 d = vec2(1.0);
	d.x = r1 < 1.0 ? sqrt(r1) - 1.0 : 1.0 - sqrt(2.0 - r1);
        d.y = r2 < 1.0 ? sqrt(r2) - 1.0 : 1.0 - sqrt(2.0 - r2);
	
	// TODO save this as a uniform to avoid division
	d /= (uResolution * 0.5);
	d += (2.0 * vUv - 1.0);
	
	vec3 rayDir = normalize( d.x * camRight * uULen + d.y * camUp * uVLen + camForward );
	
	// depth of field
	vec3 focalPoint = uFocusDistance * rayDir;
	float randomAngle = rand() * TWO_PI; // pick random point on aperture
	float randomRadius = rand() * uApertureSize;
	vec3  randomAperturePos = ( cos(randomAngle) * camRight + sin(randomAngle) * camUp ) * randomRadius;
	// point on aperture to focal point
	vec3 finalRayDir = normalize(focalPoint - randomAperturePos);
    
	Ray ray = Ray( camPos + randomAperturePos , finalRayDir );

	SetupScene();
	
	float pattern = fract(uTime * 0.01) * 2.0 - 1.0;
	float xPos = pattern;
	float yPos = cos(pattern) - 0.68;
	float zPos = sin(pattern) * 1.5;
	vec3 sunPos = vec3(xPos, yPos, zPos);
	vec3 sunDirection = normalize(sunPos);	
	     		
	// perform path tracing and get resulting pixel color
	vec3 pixelColor = CalculateRadiance( ray, sunDirection );
	
	vec3 previousColor = texture2D(tPreviousTexture, vUv).rgb;
	
	/*
	if ( uCameraJustStartedMoving )
	{
		previousColor = vec3(0.0); // clear rendering accumulation buffer
	}
	else if ( uCameraIsMoving )
	{
		previousColor *= 0.5; // motion-blur trail amount (old image)
		pixelColor *= (uSampleCounter) * 0.5; // brightness of new image (noisy)
	}
	*/
	
	previousColor *= 0.85; // motion-blur trail amount (old image)
	pixelColor *= 0.15; // brightness of new image (noisy)
	
	gl_FragColor = vec4( pixelColor + previousColor, 1.0 );
	
}

		</script>
		
		
		<script>

			if ( ! Detector.webgl ) Detector.addGetWebGLMessage();

			var SCREEN_WIDTH = window.innerWidth;
			var SCREEN_HEIGHT = window.innerHeight;
			var container, stats;
			var controls;
			var pathTracingScene, screenTextureScene, screenOutputScene;
			var pathTracingUniforms, screenTextureUniforms, screenOutputUniforms;
			var pathTracingDefines;
			var pathTracingGeometry, pathTracingMaterial, pathTracingMesh;
			var screenTextureGeometry, screenTextureMaterial, screenTextureMesh;
			var screenOutputGeometry, screenOutputMaterial, screenOutputMesh;
			var tallBoxGeometry, tallBoxMaterial, tallBoxMesh;
			var shortBoxGeometry, shortBoxMaterial, shortBoxMesh;
			var pathTracingRenderTarget, screenOutputRenderTarget;
			var quadCamera, worldCamera;
			var renderer, clock;
			var frameTime, elapsedTime;
			var fovScale;
			var increaseFOV = false;
			var decreaseFOV = false;
			var apertureSize = 0.0;
			var increaseAperture = false;
			var decreaseAperture = false;
			var focusDistance = 1160.0;
			var increaseFocusDist = false;
			var decreaseFocusDist = false;
			var pixelRatio = window.devicePixelRatio * 0.5;
			var TWO_PI = Math.PI * 2;
			var randomVector = new THREE.Vector3();
			var sampleCounter = 1.0;
			var keyboard = new THREEx.KeyboardState();
			var cameraIsMoving = false;
			var cameraJustStartedMoving = false;
			var cameraRecentlyMoving = false;
			var isPaused = true;
			var oldYawRotation, oldPitchRotation;
			var mobileJoystickControls = null;
			var oldDeltaX = 0, oldDeltaY = 0;
			var newDeltaX = 0, newDeltaY = 0;
			var mobileControlsMoveX = 0;
			var mobileControlsMoveY = 0;
			var stillFlagX = true, stillFlagY = true;
			var oldPinchWidthX = 0;
			var oldPinchWidthY = 0;
			var pinchDeltaX = 0;
			var pinchDeltaY = 0;
			var camFlightSpeed = 300;
			var fontAspect;
			
			// the following variables will be used to calculate rotations and directions from the camera
			var cameraDirectionVector = new THREE.Vector3();//for moving where the camera is looking
			var cameraRightVector = new THREE.Vector3();//for strafing the camera right and left
			var cameraUpVector = new THREE.Vector3();//for moving camera up and down
			var cameraWorldQuaternion = new THREE.Quaternion();//for rotating scene objects to match camera's current rotation
			var cameraControlsObject;//for positioning and moving the camera itself
			var cameraControlsYawObject;//allows access to control camera's left/right movements through mobile input
			var cameraControlsPitchObject;//allows access to control camera's up/down movements through mobile input

			var PI_2 = Math.PI / 2;//used by controls below
			
			var infoElement = document.getElementById( 'info' );
			infoElement.style.cursor = "default";
			infoElement.style.webkitUserSelect = "none";
			infoElement.style.MozUserSelect = "none";
			
			var cameraInfoElement = document.getElementById( 'cameraInfo' );
			cameraInfoElement.style.cursor = "default";
			cameraInfoElement.style.webkitUserSelect = "none";
			cameraInfoElement.style.MozUserSelect = "none";
			
			var mouseControl = true;

			if ( 'createTouch' in document ) {
				mouseControl = false;
				pixelRatio = window.devicePixelRatio * 0.15;
				
				mobileJoystickControls = new MobileJoystickControls ({
					//showJoystick: true,
					enableMultiTouch: true
				});	
			}
			
			// if on mobile device, unpause the app because there is no ESC key and no mouse capture to do
			if ( !mouseControl )
				isPaused = false;
			
			if (mouseControl) {

				window.addEventListener( 'wheel', onMouseWheel, false );
				
				document.body.addEventListener("click", function() {
					this.requestPointerLock = this.requestPointerLock || this.mozRequestPointerLock;
					this.requestPointerLock();
				}, false);

				window.addEventListener("click", function(event) {
					event.preventDefault();	
				}, false);
				window.addEventListener("dblclick", function(event) {
					event.preventDefault();	
				}, false);


				var pointerlockChange = function ( event ) {

					if ( document.pointerLockElement === document.body || 
					    document.mozPointerLockElement === document.body || document.webkitPointerLockElement === document.body ) {

						isPaused = false;

					} else {

						isPaused = true;

					}

				};

				// Hook pointer lock state change events
				document.addEventListener( 'pointerlockchange', pointerlockChange, false );
				document.addEventListener( 'mozpointerlockchange', pointerlockChange, false );
				document.addEventListener( 'webkitpointerlockchange', pointerlockChange, false );

			}
			
			function onMouseWheel( event ) {

				event.preventDefault();
				event.stopPropagation();

				if ( event.deltaY > 0 ) {
					
					increaseFOV = true;
				
				} else if ( event.deltaY < 0 ) {
					
					decreaseFOV = true;
					
				}

			}
			
			
			init();					
		     // function init( meshes ) {
			function init() {
				
				renderer = new THREE.WebGLRenderer();
				renderer.autoClear = false;
				// 1 is full resolution, 0.5 is half, 0.25 is quarter, etc. (must be > than 0.0)
				renderer.setPixelRatio(pixelRatio);
				renderer.setSize( window.innerWidth, window.innerHeight );
				renderer.context.getExtension('OES_texture_float');
				
				container = document.getElementById( 'container' );
				container.appendChild( renderer.domElement );
		      
				stats = new Stats();
				stats.domElement.style.position = 'absolute';
				stats.domElement.style.top = '0px';
				stats.domElement.style.cursor = "default";
				stats.domElement.style.webkitUserSelect = "none";
				stats.domElement.style.MozUserSelect = "none";
				container.appendChild( stats.domElement );
				
				window.addEventListener( 'resize', onWindowResize, false );
				
				clock = new THREE.Clock();
				
				pathTracingScene = new THREE.Scene();
				screenTextureScene = new THREE.Scene();
				screenOutputScene = new THREE.Scene();
				
				// quadCamera is simply the camera to help render the full screen quad (2 triangles),
				// hence the name.  It is an Orthographic camera that sits facing the view plane, which serves as
				// the window into our 3d world. This camera will not move or rotate for the duration of the app.
				quadCamera = new THREE.OrthographicCamera( -1, 1, 1, -1, 0, 1 );
				screenTextureScene.add(quadCamera);
				screenOutputScene.add(quadCamera);
				
				// worldCamera is the dynamic camera 3d object that will be positioned, oriented and 
				// constantly updated inside the 3d scene.  Its view will ultimately get passed back to the 
				// stationary quadCamera, which renders the scene to a fullscreen quad (made up of 2 large triangles).
				worldCamera = new THREE.PerspectiveCamera(50, window.innerWidth / window.innerHeight, 1, 1000);
				pathTracingScene.add(worldCamera);
				
				controls = new FirstPersonCameraControls( worldCamera );
							
				cameraControlsObject = controls.getObject();
				cameraControlsYawObject = controls.getYawObject();
				cameraControlsPitchObject = controls.getPitchObject();
				
				pathTracingScene.add( cameraControlsObject );

				// for flyCam
				cameraControlsObject.position.set(278, 270, 1050); //270 Y
				///cameraControlsYawObject.rotation.y = 0.0;
				// look slightly upward
				cameraControlsPitchObject.rotation.x = 0.005;
				
				oldYawRotation = cameraControlsYawObject.rotation.y;
				oldPitchRotation = cameraControlsPitchObject.rotation.x;
				
				// now that we moved and rotated the camera, the following line force-updates the camera's matrix,
				//  and prevents rendering the very first frame in the old default camera position/orientation
				cameraControlsObject.updateMatrixWorld(true);
				
				pathTracingRenderTarget = new THREE.WebGLRenderTarget( (window.innerWidth * pixelRatio), (window.innerHeight * pixelRatio), {
					minFilter: THREE.NearestFilter,
					magFilter: THREE.NearestFilter,
					format: THREE.RGBAFormat,
					type: THREE.FloatType,
					depthBuffer: false,
					stencilBuffer: false
				} );
				pathTracingRenderTarget.texture.generateMipmaps = false;
				
				screenTextureRenderTarget = new THREE.WebGLRenderTarget( (window.innerWidth * pixelRatio), (window.innerHeight * pixelRatio), {
					minFilter: THREE.NearestFilter, 
					magFilter: THREE.NearestFilter,
					format: THREE.RGBAFormat,
					type: THREE.FloatType,
					depthBuffer: false,
					stencilBuffer: false
				} );
				screenTextureRenderTarget.texture.generateMipmaps = false;
				
				
				pathTracingGeometry = new THREE.PlaneBufferGeometry( 2, 2 );

				pathTracingUniforms = {
					
					tPreviousTexture: { type: "t", value: screenTextureRenderTarget.texture },
					//tTriangleTexture: { type: "t", value: triangleDataTexture },
					
					uCameraIsMoving: { type: "b1", value: false },
					uCameraJustStartedMoving: { type: "b1", value: false },
					uTime: { type: "f", value: 0.0 },
					uSampleCounter: { type: "f", value: 0.0 },
					uULen: { type: "f", value: 1.0 },
					uVLen: { type: "f", value: 1.0 },
					uApertureSize: { type: "f", value: 0.0 },
					uFocusDistance: { type: "f", value: 1160.0 },
					
					uResolution: { type: "v2", value: new THREE.Vector2() },
					
					//uMeshBBox_min: { type: "v3", value: objMeshes.my_mesh.bounding_box_min },
					//uMeshBBox_max: { type: "v3", value: objMeshes.my_mesh.bounding_box_max },
					uRandomVector: { type: "v3", value: new THREE.Vector3() },
				
					uCameraMatrix: { type: "m4", value: new THREE.Matrix4() },
					
					uTallBoxMeshMatrix: { type: "m4", value: new THREE.Matrix4() },
					uTallBoxMeshInvMatrix: { type: "m4", value: new THREE.Matrix4() },
					uShortBoxMeshMatrix: { type: "m4", value: new THREE.Matrix4() },
					uShortBoxMeshInvMatrix: { type: "m4", value: new THREE.Matrix4() },
					
					uShortBoxMatrix4x4: { type: "m4", value: new THREE.Matrix4() },
					uShortBoxNormalMatrix3x3: { type: "m3", value: new THREE.Matrix3() },
					uTallBoxMatrix4x4: { type: "m4", value: new THREE.Matrix4() },
					uTallBoxNormalMatrix3x3: { type: "m3", value: new THREE.Matrix3() }
	
				};
				
				/*
				pathTracingDefines = {
					NUMBER_OF_TRIANGLES: total_number_of_triangles
				};
				*/
			
				pathTracingMaterial = new THREE.ShaderMaterial( {
					uniforms: pathTracingUniforms,
					//defines: pathTracingDefines,
					vertexShader: document.getElementById( 'pathTracingVertexShader' ).textContent,
					fragmentShader: document.getElementById( 'pathTracingFragmentShader' ).textContent,
				        depthTest: false,
                                        depthWrite: false
                                } );

				pathTracingMesh = new THREE.Mesh( pathTracingGeometry, pathTracingMaterial );
				pathTracingScene.add( pathTracingMesh );
				
				
				
				// the following keeps the large scene ShaderMaterial quad right in front 
				//   of the camera at all times. This is necessary because without it, the scene 
				//   quad will fall out of view and get clipped when the camera rotates past 180 degrees.
				worldCamera.add( pathTracingMesh );
				
				
				
				screenTextureGeometry = new THREE.PlaneBufferGeometry( 2, 2 );
				
				screenTextureUniforms = {
					tTexture0: { type: "t", value: pathTracingRenderTarget.texture }
				}
				
				screenTextureMaterial = new THREE.ShaderMaterial( {
					uniforms: screenTextureUniforms,
					vertexShader: document.getElementById( 'screenTextureVertexShader' ).textContent,
					fragmentShader: document.getElementById( 'screenTextureFragmentShader' ).textContent,
					depthWrite: false,
					depthTest: false
				} );
				
				screenTextureMesh = new THREE.Mesh(screenTextureGeometry, screenTextureMaterial);
				screenTextureScene.add(screenTextureMesh);
				
				
				
			
				screenOutputGeometry = new THREE.PlaneBufferGeometry( 2, 2 );
				
				screenOutputUniforms = {
					uOneOverSampleCounter: { type: "f", value: 0.0 },
					tTexture0: { type: "t", value: pathTracingRenderTarget.texture }
				}
				
				screenOutputMaterial = new THREE.ShaderMaterial( {
					uniforms: screenOutputUniforms,
					vertexShader: document.getElementById( 'screenOutputVertexShader' ).textContent,
					fragmentShader: document.getElementById( 'screenOutputFragmentShader' ).textContent,
					depthWrite: false,
					depthTest: false
				} );
				
				screenOutputMesh = new THREE.Mesh(screenOutputGeometry, screenOutputMaterial);
				screenOutputScene.add(screenOutputMesh);
				
				// Boxes
				tallBoxGeometry = new THREE.BoxGeometry(1,1,1);
				tallBoxMaterial = new THREE.MeshPhysicalMaterial( {
					color: new THREE.Color(0.95, 0.95, 0.95), //RGB, ranging from 0.0 - 1.0
					roughness: 1.0 // ideal Diffuse material	
				} );
				
				tallBoxMesh = new THREE.Mesh(tallBoxGeometry, tallBoxMaterial);
				pathTracingScene.add(tallBoxMesh);
				tallBoxMesh.visible = false; // disable normal Three.js rendering updates of this object: 
				// it is just a data placeholder as well as an Object3D that can be transformed/manipulated by 
				// using familiar Three.js library commands. It is then fed into the GPU path tracing renderer
				// through its 'matrixWorld' matrix. See below:
				tallBoxMesh.rotation.set(0, Math.PI * 0.1, 0);
				tallBoxMesh.position.set(180, 170, -350);
				tallBoxMesh.updateMatrixWorld(true); // 'true' forces immediate matrix update
				pathTracingUniforms.uTallBoxMeshMatrix.value.copy( tallBoxMesh.matrixWorld );
				pathTracingUniforms.uTallBoxMeshInvMatrix.value.getInverse( tallBoxMesh.matrixWorld );
				
				pathTracingUniforms.uTallBoxMatrix4x4.value.getInverse( tallBoxMesh.matrixWorld );
				pathTracingUniforms.uTallBoxNormalMatrix3x3.value.getNormalMatrix( tallBoxMesh.matrixWorld );
				
				shortBoxGeometry = new THREE.BoxGeometry(1,1,1);
				shortBoxMaterial = new THREE.MeshPhysicalMaterial( {
					color: new THREE.Color(0.95, 0.95, 0.95), //RGB, ranging from 0.0 - 1.0
					roughness: 1.0 // ideal Diffuse material	
				} );
				
				shortBoxMesh = new THREE.Mesh(shortBoxGeometry, shortBoxMaterial);
				pathTracingScene.add(shortBoxMesh);
				shortBoxMesh.visible = false;
				shortBoxMesh.rotation.set(0, -Math.PI * 0.09, 0);
				shortBoxMesh.position.set(370, 85, -170);
				shortBoxMesh.updateMatrixWorld(true); // 'true' forces immediate matrix update
				pathTracingUniforms.uShortBoxMeshMatrix.value.copy( shortBoxMesh.matrixWorld );
				pathTracingUniforms.uShortBoxMeshInvMatrix.value.getInverse( shortBoxMesh.matrixWorld );
				
				pathTracingUniforms.uShortBoxMatrix4x4.value.getInverse( shortBoxMesh.matrixWorld );
				pathTracingUniforms.uShortBoxNormalMatrix3x3.value.getNormalMatrix( shortBoxMesh.matrixWorld );

				/*
				// Fullscreen API
				document.addEventListener("click", function() {
					
					if ( !document.fullscreenElement && !document.mozFullScreenElement && !document.webkitFullscreenElement ) {

						if (document.documentElement.requestFullscreen) {
							document.documentElement.requestFullscreen();
							
						} else if (document.documentElement.mozRequestFullScreen) {
							document.documentElement.mozRequestFullScreen();
						
						} else if (document.documentElement.webkitRequestFullscreen) {
							document.documentElement.webkitRequestFullscreen();
						
						}

					}
				});
				*/
				
				// onWindowResize() must be at the end of the init() function
				onWindowResize();
				
				// everything is set up, now we can start animating
				animate();
				
			} // end function init()
			
			

			function onWindowResize( event ) {
				
				SCREEN_WIDTH = window.innerWidth;
				SCREEN_HEIGHT = window.innerHeight;
				
				renderer.setPixelRatio(pixelRatio);
				renderer.setSize( SCREEN_WIDTH, SCREEN_HEIGHT );
				
				fontAspect = (SCREEN_WIDTH / 175) * (SCREEN_HEIGHT / 200);
				if (fontAspect > 25) fontAspect = 25;
				if (fontAspect < 4) fontAspect = 4;
				fontAspect *= 2;
				
				pathTracingUniforms.uResolution.value.x = SCREEN_WIDTH * pixelRatio;
				pathTracingUniforms.uResolution.value.y = SCREEN_HEIGHT * pixelRatio;
				
				pathTracingRenderTarget.setSize( SCREEN_WIDTH * pixelRatio, SCREEN_HEIGHT * pixelRatio );
				screenTextureRenderTarget.setSize( SCREEN_WIDTH * pixelRatio, SCREEN_HEIGHT * pixelRatio );
				
				worldCamera.aspect = SCREEN_WIDTH / SCREEN_HEIGHT;
				worldCamera.updateProjectionMatrix();
				
				// the following scales all scene objects by the worldCamera's field of view,
				// taking into account the screen aspect ratio and multiplying the uniform uULen,
				// the x-coordinate, by this ratio
				fovScale = worldCamera.fov * 0.5 * (Math.PI / 180.0);
				pathTracingUniforms.uVLen.value = Math.tan(fovScale);
				pathTracingUniforms.uULen.value = pathTracingUniforms.uVLen.value * worldCamera.aspect;
				
				if ( !mouseControl ) {
					
					button1Element.style.display = "";
					button2Element.style.display = "";
					button3Element.style.display = "";
					button4Element.style.display = "";
					button5Element.style.display = "";
					button6Element.style.display = "";
					// check if mobile device is in portrait or landscape mode and position buttons accordingly
					if (SCREEN_WIDTH < SCREEN_HEIGHT) {
						
						button1Element.style.right = 36 + "%";
						button2Element.style.right = 2 + "%";
						button3Element.style.right = 16 + "%";
						button4Element.style.right = 16 + "%";
						button5Element.style.right = 3 + "%";
						button6Element.style.right = 3 + "%";

						button1Element.style.bottom = 5 + "%";
						button2Element.style.bottom = 5 + "%";
						button3Element.style.bottom = 13 + "%";
						button4Element.style.bottom = 2 + "%";
						button5Element.style.bottom = 25 + "%";
						button6Element.style.bottom = 18 + "%";
						
					}
					else {
						
						button1Element.style.right = 22 + "%";
						button2Element.style.right = 3 + "%";
						button3Element.style.right = 11 + "%";
						button4Element.style.right = 11 + "%";
						button5Element.style.right = 3 + "%";
						button6Element.style.right = 3 + "%";

						button1Element.style.bottom = 10 + "%";
						button2Element.style.bottom = 10 + "%";
						button3Element.style.bottom = 26 + "%";
						button4Element.style.bottom = 4 + "%";
						button5Element.style.bottom = 48 + "%";
						button6Element.style.bottom = 34 + "%";
						
					}
					
				} // end if ( !mouseControl ) {
				
			} // end function onWindowResize( event )
			


			function animate() {
				
				requestAnimationFrame( animate );
				
				frameTime = clock.getDelta();
				
				elapsedTime = clock.getElapsedTime() % 1000;
				
				// reset flags
				cameraIsMoving = false;
				cameraJustStartedMoving = false;
				
				// check user controls
				if (mouseControl) {
					// movement detected
					if ( oldYawRotation != cameraControlsYawObject.rotation.y || 
					      oldPitchRotation != cameraControlsPitchObject.rotation.x ) {
	
						cameraIsMoving = true;
					}
					
					// save state for next frame
					oldYawRotation = cameraControlsYawObject.rotation.y;
					oldPitchRotation = cameraControlsPitchObject.rotation.x;
					
				} // end if (mouseControl)
			
				// if not playing on desktop, get input from the mobileJoystickControls
				if ( !mouseControl ) {

					newDeltaX = joystickDeltaX;
					
					if (newDeltaX) {
						
						mobileControlsMoveX = oldDeltaX - newDeltaX;
						// smooth out jerkiness if camera was sitting still 
						if (stillFlagX) {
							mobileControlsMoveX *= 0.1;
							stillFlagX = false;
						}
						// mobileJoystick X movement (left and right) affects camera rotation around the Y axis	
						cameraControlsYawObject.rotation.y += (mobileControlsMoveX) * 0.01;
					}
					
					newDeltaY = joystickDeltaY;
					
					if (newDeltaY) {
						
						mobileControlsMoveY = oldDeltaY - newDeltaY;
						// smooth out jerkiness if camera was sitting still
						if (stillFlagY) {
							mobileControlsMoveY *= 0.1;
							stillFlagY = false;
						}
						// mobileJoystick Y movement (up and down) affects camera rotation around the X axis	
						cameraControlsPitchObject.rotation.x += (mobileControlsMoveY) * 0.01;
					}
					
					// clamp the camera's vertical movement (around the x-axis) to the scene's 'ceiling' and 'floor',
					// so you can't accidentally flip the camera upside down
					cameraControlsPitchObject.rotation.x = Math.max( - PI_2, Math.min( PI_2, cameraControlsPitchObject.rotation.x ) );
					
					// save state for next frame
					oldDeltaX = newDeltaX;
					oldDeltaY = newDeltaY;
					
					// movement detected
					if ( newDeltaX || newDeltaY ) {
						
						cameraIsMoving = true;
					}
					else {
						stillFlagX = true;
						stillFlagY = true;
					}
					
					newPinchWidthX = pinchWidthX;
					newPinchWidthY = pinchWidthY;
					pinchDeltaX = newPinchWidthX - oldPinchWidthX;
					pinchDeltaY = newPinchWidthY - oldPinchWidthY;
					
					if( Math.abs(pinchDeltaX) > Math.abs(pinchDeltaY) ) {
						if (pinchDeltaX < -3) increaseFOV = true;
						if (pinchDeltaX >  3) decreaseFOV = true;
					}
					
					if( Math.abs(pinchDeltaY) >= Math.abs(pinchDeltaX) ) {
						if (pinchDeltaY >  1) increaseAperture = true;
						if (pinchDeltaY < -1) decreaseAperture = true;
					}
					
					// save state for next frame
					oldPinchWidthX = newPinchWidthX;
					oldPinchWidthY = newPinchWidthY;
					
				} // end if ( !mouseControl )
				
				// this gives us a vector in the direction that the camera is pointing,
				// which will be useful for moving the camera 'forward' and shooting projectiles in that direction
				controls.getDirection(cameraDirectionVector);
				cameraDirectionVector.normalize();
				controls.getUpVector(cameraUpVector);
				controls.getRightVector(cameraRightVector);

				// the following gives us a rotation quaternion (4D vector), which will be useful for 
				// rotating scene objects to match the camera's rotation
				worldCamera.getWorldQuaternion(cameraWorldQuaternion);
				
				// allow flying camera
				if ( (keyboard.pressed('W') || button3Pressed) && !(keyboard.pressed('S') || button4Pressed) ) {

					cameraControlsObject.position.add(cameraDirectionVector.multiplyScalar(camFlightSpeed * frameTime));
					cameraIsMoving = true;
				}
				if ( (keyboard.pressed('S') || button4Pressed) && !(keyboard.pressed('W') || button3Pressed) ) {

					cameraControlsObject.position.sub(cameraDirectionVector.multiplyScalar(camFlightSpeed * frameTime));
					cameraIsMoving = true;
				}
				if ( (keyboard.pressed('A') || button1Pressed) && !(keyboard.pressed('D') || button2Pressed) ) {

					cameraControlsObject.position.sub(cameraRightVector.multiplyScalar(camFlightSpeed * frameTime));
					cameraIsMoving = true;
				}
				if ( (keyboard.pressed('D') || button2Pressed) && !(keyboard.pressed('A') || button1Pressed) ) {

					cameraControlsObject.position.add(cameraRightVector.multiplyScalar(camFlightSpeed * frameTime));
					cameraIsMoving = true;
				}
				if ( keyboard.pressed('Q') && !keyboard.pressed('Z') ) {

					cameraControlsObject.position.add(cameraUpVector.multiplyScalar(camFlightSpeed * frameTime));
					cameraIsMoving = true;
				}
				if ( keyboard.pressed('Z') && !keyboard.pressed('Q') ) {

					cameraControlsObject.position.sub(cameraUpVector.multiplyScalar(camFlightSpeed * frameTime));
					cameraIsMoving = true;
				}
				if ( (keyboard.pressed('up') || button5Pressed) && !(keyboard.pressed('down') || button6Pressed) ) {
					
					increaseFocusDist = true;
				}
				if ( (keyboard.pressed('down') || button6Pressed) && !(keyboard.pressed('up') || button5Pressed) ) {
					
					decreaseFocusDist = true;
				}
				if ( keyboard.pressed('right') && !keyboard.pressed('left') ) {
					
					increaseAperture = true;
				}
				if ( keyboard.pressed('left') && !keyboard.pressed('right') ) {
					
					decreaseAperture = true;
				}
				
				if ( increaseFOV ) {
					worldCamera.fov ++;
					if (worldCamera.fov > 150)
						worldCamera.fov = 150;
					fovScale = worldCamera.fov * 0.5 * (Math.PI / 180.0);
					pathTracingUniforms.uVLen.value = Math.tan(fovScale);
					pathTracingUniforms.uULen.value = pathTracingUniforms.uVLen.value * worldCamera.aspect;
				
					cameraIsMoving = true;
					increaseFOV = false;
				}
				if ( decreaseFOV ) {
					worldCamera.fov --;
					if (worldCamera.fov < 1)
						worldCamera.fov = 1;
					fovScale = worldCamera.fov * 0.5 * (Math.PI / 180.0);
					pathTracingUniforms.uVLen.value = Math.tan(fovScale);
					pathTracingUniforms.uULen.value = pathTracingUniforms.uVLen.value * worldCamera.aspect;
					
					cameraIsMoving = true;
					decreaseFOV = false;
				}
				
				if (increaseFocusDist) {
					focusDistance += 2;
					pathTracingUniforms.uFocusDistance.value = focusDistance;
					cameraIsMoving = true;
					increaseFocusDist = false;
				}
				if (decreaseFocusDist) {
					focusDistance -= 2;
					if (focusDistance < 2)
						focusDistance = 2;
					pathTracingUniforms.uFocusDistance.value = focusDistance;
					cameraIsMoving = true;
					decreaseFocusDist = false;
				}
				
				if (increaseAperture) {
					apertureSize += 1.0;
					if (apertureSize > 200.0)
						apertureSize = 200.0;
					pathTracingUniforms.uApertureSize.value = apertureSize;
					cameraIsMoving = true;
					increaseAperture = false;
				}
				if (decreaseAperture) {
					apertureSize -= 1.0;
					if (apertureSize < 0.0)
						apertureSize = 0.0;
					pathTracingUniforms.uApertureSize.value = apertureSize;
					cameraIsMoving = true;
					decreaseAperture = false;
				}
				
				
				if ( cameraIsMoving ) {
					
					sampleCounter = 1.0;
					
					if ( !cameraRecentlyMoving ) {
						cameraJustStartedMoving = true;
						cameraRecentlyMoving = true;
					}
					
				}
				
				if ( !cameraIsMoving ) {
	
					sampleCounter = 1.0;
					cameraRecentlyMoving = false;
					
				}
					
				pathTracingUniforms.uTime.value = elapsedTime;
				pathTracingUniforms.uCameraIsMoving.value = cameraIsMoving;
				pathTracingUniforms.uCameraJustStartedMoving.value = cameraJustStartedMoving;
				pathTracingUniforms.uSampleCounter.value = sampleCounter;
				screenOutputUniforms.uOneOverSampleCounter.value = 1.0 / sampleCounter;
				pathTracingUniforms.uRandomVector.value = randomVector.set( Math.random(), Math.random(), Math.random() );
				// CAMERA
				cameraControlsObject.updateMatrixWorld(true);			
				pathTracingUniforms.uCameraMatrix.value.copy( worldCamera.matrixWorld );
				
				cameraInfoElement.innerHTML = "FOV: " + worldCamera.fov + " / Aperture: " + apertureSize.toFixed(2) + " / FocusDistance: " + focusDistance + "<br>" + "Samples: " + sampleCounter;
				
				
				// RENDERING in 3 steps
				
				// STEP 1
				// Perform PathTracing and Render(save) into pathTracingRenderTarget
				// Read previous screenTextureRenderTarget to use as a new starting point to blend with
				renderer.render( pathTracingScene, worldCamera, pathTracingRenderTarget );	
				
				// STEP 2
				// Render(copy) the final pathTracingScene output(above) into screenTextureRenderTarget
				// This will be used as a new starting point for Step 1 above
				renderer.render( screenTextureScene, quadCamera, screenTextureRenderTarget );
				
				// STEP 3
				// Render full screen quad with generated pathTracingRenderTarget in STEP 1 above.
				// After the image is gamma corrected, it will be shown on the screen as the final accumulated output
				renderer.render( screenOutputScene, quadCamera );
						
				
				stats.update();
					
				
			} // end function animate()

		</script>

	</body>
</html>